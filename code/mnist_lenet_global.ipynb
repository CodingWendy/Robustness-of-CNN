{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global robustness of lenet5 model (mnist dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist \n",
    "import matplotlib.pyplot as plt \n",
    "from keras.optimizers import Adam \n",
    "from keras import utils \n",
    "import numpy as np \n",
    "import math\n",
    "from tensorflow.keras.models import load_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mnist\n",
    "(x_train, y_train), (x_test, y_test) = dataset.load_data() #translate the data to image \n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], -1).astype(\"float64\") \n",
    "x_test = x_test.reshape(x_test.shape[0], -1).astype(\"float64\")\n",
    "\n",
    "#normalization \n",
    "x_train /= 255 \n",
    "x_test /= 255\n",
    "\n",
    "#translate y_train and y_test to “one hot” form \n",
    "y_train = utils.to_categorical(y_train) \n",
    "\n",
    "x_train = x_train.reshape(-1, 28, 28, 1) \n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "lenet5 = load_model('Model/lenet5_mnist.h5')#load lenet5 model trained with mnist dataset \n",
    "lenet5.compile(optimizer=Adam(),loss='sparse_categorical_crossentropy',metrics=['accuracy']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta is reduced by 0.0001, the new beta is 0.1119\n",
      "Beta is reduced by 0.0001, the new beta is 0.1118\n",
      "Beta is reduced by 0.0001, the new beta is 0.1117\n",
      "Beta is reduced by 0.0001, the new beta is 0.11159999999999999\n",
      "Beta is reduced by 0.0001, the new beta is 0.11149999999999999\n",
      "Beta is reduced by 0.0001, the new beta is 0.11139999999999999\n",
      "Beta is reduced by 0.0001, the new beta is 0.11129999999999998\n",
      "Beta is reduced by 0.0001, the new beta is 0.11119999999999998\n",
      "Beta is reduced by 0.0001, the new beta is 0.11109999999999998\n",
      "Beta is reduced by 0.0001, the new beta is 0.11099999999999997\n",
      "Beta is reduced by 0.0001, the new beta is 0.11089999999999997\n",
      "Beta is reduced by 0.0001, the new beta is 0.11079999999999997\n",
      "Beta is reduced by 0.0001, the new beta is 0.11069999999999997\n",
      "Beta is reduced by 0.0001, the new beta is 0.11059999999999996\n",
      "Beta is reduced by 0.0001, the new beta is 0.11049999999999996\n",
      "Beta is reduced by 0.0001, the new beta is 0.11039999999999996\n",
      "Beta is reduced by 0.0001, the new beta is 0.11029999999999995\n",
      "Beta is reduced by 0.0001, the new beta is 0.11019999999999995\n",
      "Beta is reduced by 0.0001, the new beta is 0.11009999999999995\n",
      "Beta is reduced by 0.0001, the new beta is 0.10999999999999995\n",
      "Beta is reduced by 0.0001, the new beta is 0.10989999999999994\n",
      "Beta is reduced by 0.0001, the new beta is 0.10979999999999994\n",
      "Beta is reduced by 0.0001, the new beta is 0.10969999999999994\n",
      "Beta is reduced by 0.0001, the new beta is 0.10959999999999993\n",
      "Beta is reduced by 0.0001, the new beta is 0.10949999999999993\n",
      "Beta is reduced by 0.0001, the new beta is 0.10939999999999993\n",
      "Beta is reduced by 0.0001, the new beta is 0.10929999999999992\n",
      "Beta is reduced by 0.0001, the new beta is 0.10919999999999992\n",
      "Beta is reduced by 0.0001, the new beta is 0.10909999999999992\n",
      "Beta is reduced by 0.0001, the new beta is 0.10899999999999992\n",
      "Beta is reduced by 0.0001, the new beta is 0.10889999999999991\n",
      "Beta is reduced by 0.0001, the new beta is 0.10879999999999991\n",
      "Beta is reduced by 0.0001, the new beta is 0.10869999999999991\n",
      "Beta is reduced by 0.0001, the new beta is 0.1085999999999999\n",
      "Beta is reduced by 0.0001, the new beta is 0.1084999999999999\n",
      "Beta is reduced by 0.0001, the new beta is 0.1083999999999999\n",
      "Beta is reduced by 0.0001, the new beta is 0.1082999999999999\n",
      "Beta is reduced by 0.0001, the new beta is 0.1081999999999999\n",
      "Beta is reduced by 0.0001, the new beta is 0.10809999999999989\n",
      "Beta is reduced by 0.0001, the new beta is 0.10799999999999989\n",
      "Beta is reduced by 0.0001, the new beta is 0.10789999999999988\n",
      "Beta is reduced by 0.0001, the new beta is 0.10779999999999988\n",
      "Beta is reduced by 0.0001, the new beta is 0.10769999999999988\n",
      "Beta is reduced by 0.0001, the new beta is 0.10759999999999988\n",
      "Beta is reduced by 0.0001, the new beta is 0.10749999999999987\n",
      "Beta is reduced by 0.0001, the new beta is 0.10739999999999987\n",
      "Beta is reduced by 0.0001, the new beta is 0.10729999999999987\n",
      "Beta is reduced by 0.0001, the new beta is 0.10719999999999986\n",
      "Beta is reduced by 0.0001, the new beta is 0.10709999999999986\n",
      "Beta is reduced by 0.0001, the new beta is 0.10699999999999986\n",
      "Beta is reduced by 0.0001, the new beta is 0.10689999999999986\n",
      "Beta is reduced by 0.0001, the new beta is 0.10679999999999985\n",
      "Beta is reduced by 0.0001, the new beta is 0.10669999999999985\n",
      "Beta is reduced by 0.0001, the new beta is 0.10659999999999985\n",
      "Beta is reduced by 0.0001, the new beta is 0.10649999999999984\n",
      "Beta is reduced by 0.0001, the new beta is 0.10639999999999984\n",
      "Beta is reduced by 0.0001, the new beta is 0.10629999999999984\n",
      "global robustness formula satisfied\n",
      "max safe distance: 0.10629999999999984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10629999999999984"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta = 0.11200\n",
    "sample(x_test,y_test,beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global robustness Sample Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(x_test,y_test,beta):\n",
    "    \n",
    "    \n",
    "    mean = np.zeros(2)  \n",
    "    cov = np.eye(2)\n",
    "    \n",
    "    for i in range(x_test.shape[0]):\n",
    "        count = 0\n",
    "        while True:\n",
    "            p = np.random.multivariate_normal(mean, cov,(28,28)) #sample formula\n",
    "            p = p.reshape(-1,28,28,1)\n",
    "            neighbour = p[0] + x_test[i]*255\n",
    "            neighbour /= 255\n",
    "            distance=np.linalg.norm(p[0]) \n",
    "            distance /= 255\n",
    "            if (distance < beta or distance == beta):\n",
    "                #print(distance)\n",
    "                output = lenet5.predict(neighbour.reshape(-1, 28, 28, 1),batch_size=128)[0]\n",
    "                proba = softmax(output)\n",
    "                pred = np.argmax(proba)\n",
    "                label = y_test[i]\n",
    "                if(pred == label): \n",
    "                    count+=1\n",
    "                else:  #if there are some iamges inside beta cannot have the same label, beta will be decreased\n",
    "                    beta = beta-0.0001\n",
    "                    print(\"Beta is reduced by 0.0001, the new beta is\",beta)  \n",
    "                    i-=1\n",
    "                    break\n",
    "                    \n",
    "            if(count<600):  \n",
    "                continue\n",
    "                \n",
    "            if(count==600):  \n",
    "                #local robustness formula satisfied\n",
    "                break\n",
    "                \n",
    "    print(\"global robustness formula satisfied\") \n",
    "    print(\"max safe distance:\",beta)\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x-np.max(x))\n",
    "    return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
