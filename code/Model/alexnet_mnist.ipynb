{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation, Flatten, Dense,Dropout\n",
    "import keras\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_alexnet(inputShape):\n",
    "    # Define the input layer\n",
    "    inputs = keras.Input(shape = inputShape)\n",
    "\n",
    "    #converlutional layer 1\n",
    "    conv1 = keras.layers.Conv2D(filters= 64, kernel_size= [11, 11], strides= [1, 1], activation= keras.activations.relu, use_bias= True, padding= 'same')(inputs)    \n",
    "    pooling1 = keras.layers.AveragePooling2D(pool_size= [2, 2], strides= [2, 2], padding= 'valid')(conv1)\n",
    "    stand1 = keras.layers.BatchNormalization(axis= 1)(pooling1)\n",
    "\n",
    "    #converlutional layer 2\n",
    "    conv2 = keras.layers.Conv2D(filters= 192, kernel_size= [5, 5], strides= [1, 1], activation= keras.activations.relu, use_bias= True, padding= 'same')(stand1)\n",
    "    pooling2 = keras.layers.AveragePooling2D(pool_size= [2, 2], strides= [2, 2], padding= 'valid')(conv2)\n",
    "    \n",
    "    stand2 = keras.layers.BatchNormalization(axis= 1)(pooling2)\n",
    "\n",
    "    #converlutional layer 3\n",
    "    conv3 = keras.layers.Conv2D(filters= 384, kernel_size= [3, 3], strides= [1, 1], activation= keras.activations.relu, use_bias= True, padding= 'same')(stand2)\n",
    "    stand3 = keras.layers.BatchNormalization(axis=1)(conv3)\n",
    "\n",
    "    #converlutional layer 4\n",
    "    conv4 = keras.layers.Conv2D(filters= 384, kernel_size= [3, 3], strides= [1, 1], activation= keras.activations.relu, use_bias= True, padding= 'same')(stand3)\n",
    "    stand4 = keras.layers.BatchNormalization(axis=1)(conv4)\n",
    "\n",
    "    #converlutional layer 5\n",
    "    conv5 = keras.layers.Conv2D(filters= 256, kernel_size= [3, 3], strides= [1, 1], activation= keras.activations.relu, use_bias= True, padding= 'same')(stand4)\n",
    "    pooling5 = keras.layers.AveragePooling2D(pool_size= [2, 2], strides= [2, 2], padding= 'valid')(conv5)\n",
    "    stand5 = keras.layers.BatchNormalization(axis=1)(pooling5)\n",
    "\n",
    "    # fully connected layer\n",
    "    flatten = keras.layers.Flatten()(stand5)\n",
    "    fc1 = keras.layers.Dense(4096, activation= keras.activations.relu, use_bias= True)(flatten)\n",
    "    drop1 = keras.layers.Dropout(0.5)(fc1)\n",
    "\n",
    "    fc2 = keras.layers.Dense(4096, activation= keras.activations.relu, use_bias= True)(drop1)\n",
    "    drop2 = keras.layers.Dropout(0.5)(fc2)\n",
    "\n",
    "    fc3 = keras.layers.Dense(10, activation= keras.activations.softmax, use_bias= True)(drop2)\n",
    "    model = keras.Model(inputs= inputs, outputs = fc3)\n",
    "    \n",
    "    model.compile(optimizer= Adam(0.001),\n",
    "              loss= keras.losses.categorical_crossentropy,\n",
    "              metrics= ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mnist(dataset):\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = dataset.load_data() #original size train(xxx, 28, 28),test(xxx)\n",
    "        \n",
    "    #translate the data to image\n",
    "    x_train = x_train.reshape(x_train.shape[0], -1).astype(\"float64\")\n",
    "    x_test = x_test.reshape(x_test.shape[0], -1).astype(\"float64\")\n",
    "\n",
    "    #normalization\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "\n",
    "    #translate y_train and y_test to “one hot” form\n",
    "    y_train = utils.to_categorical(y_train) \n",
    "    y_test = utils.to_categorical(y_test)\n",
    "        \n",
    "    x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "    x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "    model = build_alexnet((28,28,1))\n",
    "    batch_size = 64\n",
    "    print(\"\\nTraining：\")\n",
    "    model.fit(x_train, y_train, batch_size, epochs=4)\n",
    "\n",
    "    # Evaluation\n",
    "    print(\"\\nEvaluation：\")\n",
    "    final_loss, final_accuracy = model.evaluate(x_test, y_test)\n",
    "    print(\"loss= \", final_loss)\n",
    "    print(\"accuracy= \", final_accuracy)\n",
    "    \n",
    "        \n",
    "    print(\"success!\")\n",
    "    model.save('alexnet_mnist.h5')\n",
    "        \n",
    "    outcome = model.predict(x_test[:1])\n",
    "    print(outcome)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training：\n",
      "Epoch 1/4\n",
      "938/938 [==============================] - 3265s 3s/step - loss: 1.0413 - accuracy: 0.7185\n",
      "Epoch 2/4\n",
      "938/938 [==============================] - 3100s 3s/step - loss: 0.1221 - accuracy: 0.9674\n",
      "Epoch 3/4\n",
      "938/938 [==============================] - 2835s 3s/step - loss: 0.0801 - accuracy: 0.9793\n",
      "Epoch 4/4\n",
      "938/938 [==============================] - 2608s 3s/step - loss: 0.0718 - accuracy: 0.9821\n",
      "\n",
      "Evaluation：\n",
      "313/313 [==============================] - 126s 399ms/step - loss: 0.0356 - accuracy: 0.9916\n",
      "loss=  0.03555772081017494\n",
      "accuracy=  0.991599977016449\n",
      "success!\n",
      "[[2.2360580e-11 2.0816005e-08 1.0460592e-09 5.0800466e-08 3.6237293e-09\n",
      "  2.0222701e-10 1.0478430e-12 9.9999833e-01 5.8541888e-10 1.6446148e-06]]\n"
     ]
    }
   ],
   "source": [
    "train_mnist(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
