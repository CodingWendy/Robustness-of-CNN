{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation, Flatten, Dense,Dropout\n",
    "from keras import backend as K \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import utils\n",
    "import sys\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.datasets import cifar10\n",
    "from keras.datasets import cifar100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_LeNet5(inputShape):\n",
    "\n",
    "    lenet5 = Sequential()\n",
    "    lenet5.add(Conv2D(filters=6, kernel_size=(5, 5), activation='relu', input_shape=inputShape))\n",
    "    lenet5.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    lenet5.add(Conv2D(16, (5, 5), activation='relu'))\n",
    "    lenet5.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    lenet5.add(Flatten())\n",
    "    lenet5.add(Dense(120, activation= \"relu\"))\n",
    "    lenet5.add(Dropout(0.5))\n",
    "    lenet5.add(Dense(84, activation= \"relu\"))\n",
    "    lenet5.add(Dropout(0.5))\n",
    "\n",
    "    lenet5.add(Dense(10))\n",
    "    lenet5.add(Activation(\"softmax\"))\n",
    "    \n",
    "    lenet5.compile(optimizer=Adam(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return lenet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cifar10(dataset):\n",
    "    \n",
    "        (x_train, y_train), (x_test, y_test) = dataset.load_data() \n",
    "        \n",
    "        #translate the data to image\n",
    "        x_train = x_train.astype(\"float32\")\n",
    "        x_test = x_test.astype(\"float32\")\n",
    "\n",
    "        #normalization\n",
    "        x_train /= 255\n",
    "        x_test /= 255\n",
    "\n",
    "        #translate y_train and y_test to “one hot” form\n",
    "        y_train = utils.to_categorical(y_train,10) \n",
    "        y_test = utils.to_categorical(y_test,10)\n",
    "        \n",
    "        \n",
    "        model = build_LeNet5(x_train.shape[1:])\n",
    "        define_batch_size = round(x_train.shape[0] * 0.001)  # batch_size\n",
    "        print(\"\\nTraining：\")\n",
    "        model.fit(x_train, y_train, batch_size= define_batch_size, epochs= 50)\n",
    "\n",
    "        # Evaluation\n",
    "        print(\"\\nEvaluation：\")\n",
    "        final_loss, final_accuracy = model.evaluate(x_test, y_test)\n",
    "        print(\"loss= \", final_loss)\n",
    "        print(\"accuracy= \", final_accuracy)\n",
    "    \n",
    "    \n",
    "        print(\"success!\")\n",
    "        model.save('lenet5_cifar10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training：\n",
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 24s 23ms/step - loss: 2.0420 - accuracy: 0.2250\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 1.6182 - accuracy: 0.4000\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 1.4899 - accuracy: 0.4584\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 1.4149 - accuracy: 0.4897\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 1.3841 - accuracy: 0.5057\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 1.3454 - accuracy: 0.5211\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 1.3205 - accuracy: 0.5289\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 1.2791 - accuracy: 0.5434\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 1.2631 - accuracy: 0.5523\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 1.2478 - accuracy: 0.5586\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 1.2281 - accuracy: 0.5672\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 1.2149 - accuracy: 0.5708\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 1.2053 - accuracy: 0.5754\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 1.1768 - accuracy: 0.5867\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 1.1740 - accuracy: 0.5869\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 1.1511 - accuracy: 0.5945\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 1.1612 - accuracy: 0.5883\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 1.1500 - accuracy: 0.5987\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 1.1413 - accuracy: 0.6002\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 1.1346 - accuracy: 0.6029\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 1.1302 - accuracy: 0.6065\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.1230 - accuracy: 0.6121\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.1034 - accuracy: 0.6157\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.1047 - accuracy: 0.6160\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.0949 - accuracy: 0.6175\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.0851 - accuracy: 0.6236\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.0810 - accuracy: 0.6192\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.0763 - accuracy: 0.6262\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 1.0648 - accuracy: 0.6287\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 1.0585 - accuracy: 0.6311\n",
      "Epoch 31/50\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 1.0627 - accuracy: 0.6298\n",
      "Epoch 32/50\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 1.0630 - accuracy: 0.6289\n",
      "Epoch 33/50\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 1.0455 - accuracy: 0.6369\n",
      "Epoch 34/50\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 1.0672 - accuracy: 0.6271\n",
      "Epoch 35/50\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 1.0296 - accuracy: 0.6424\n",
      "Epoch 36/50\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 1.0374 - accuracy: 0.6365\n",
      "Epoch 37/50\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 1.0505 - accuracy: 0.6347\n",
      "Epoch 38/50\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 1.0334 - accuracy: 0.6386\n",
      "Epoch 39/50\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 1.0292 - accuracy: 0.6415\n",
      "Epoch 40/50\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 1.0210 - accuracy: 0.6416\n",
      "Epoch 41/50\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 1.0276 - accuracy: 0.6387\n",
      "Epoch 42/50\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 1.0262 - accuracy: 0.6445\n",
      "Epoch 43/50\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 1.0150 - accuracy: 0.6470\n",
      "Epoch 44/50\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 1.0112 - accuracy: 0.6472\n",
      "Epoch 45/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.0122 - accuracy: 0.6500\n",
      "Epoch 46/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.0189 - accuracy: 0.6483\n",
      "Epoch 47/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.0162 - accuracy: 0.6468\n",
      "Epoch 48/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.0033 - accuracy: 0.6524\n",
      "Epoch 49/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.9973 - accuracy: 0.6504\n",
      "Epoch 50/50\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 1.0157 - accuracy: 0.6461\n",
      "\n",
      "Evaluation：\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 1.0533 - accuracy: 0.6383\n",
      "loss=  1.0533217191696167\n",
      "accuracy=  0.6383000016212463\n",
      "success!\n"
     ]
    }
   ],
   "source": [
    "train_cifar10(cifar10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train: 50000\n",
    "test : 10000\n",
    "train_image : (50000, 32, 32, 3)\n",
    "train_label : (50000, 1)\n",
    "test_image : (10000, 32, 32, 3)\n",
    "test_label : (10000, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
