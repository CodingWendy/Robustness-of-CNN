{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras import utils\n",
    "from keras.optimizers import SGD\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Flatten, Dense,Dropout\n",
    "from keras.datasets import cifar10\n",
    "from keras.datasets import cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG(classes):\n",
    "    model_vgg=VGG16(include_top=False,weights=\"imagenet\",input_shape=(32,32,3))\n",
    "    for layer in model_vgg.layers[:15]:\n",
    "        layer.trainable = False  #The first 15-layers of the pre-training network are frozen, \n",
    "        #and the last convolutional neural network block is trainable\n",
    "\n",
    "    top_model = Sequential()  # Customize the top-level network\n",
    "    top_model.add(Flatten(input_shape=model_vgg.output_shape[1:]))  \n",
    "    top_model.add(Dense(32, activation='relu'))  # Fully connected layer, input pixel is 32\n",
    "    top_model.add(Dropout(0.5))  \n",
    "    top_model.add(Dense(classes, activation='softmax'))  # classes is the argument\n",
    "\n",
    "    model = Model(\n",
    "    inputs=model_vgg.input,\n",
    "    outputs=top_model(model_vgg.output))  #New network = pre-trained network + custom network\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cifar100(dataset):\n",
    "    \n",
    "        (x_train, y_train), (x_test, y_test) = dataset.load_data() #original size train(xxx, 28, 28),test(xxx)\n",
    "        \n",
    "        #translate the data to image\n",
    "        x_train = x_train.astype(\"float32\")\n",
    "        x_test = x_test.astype(\"float32\")\n",
    "\n",
    "        #normalization\n",
    "        x_train /= 255\n",
    "        x_test /= 255\n",
    "        \n",
    "        #translate y_train and y_test to “one hot” form\n",
    "        y_train = utils.to_categorical(y_train,100) \n",
    "        y_test = utils.to_categorical(y_test,100)\n",
    "        \n",
    "        \n",
    "        model = VGG(100) #classes is 100\n",
    "        model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "        metrics=['accuracy']) \n",
    "        \n",
    "        print(\"\\nTraining：\")\n",
    "        model.fit(x_train, y_train, batch_size= 128, epochs= 50,verbose=1)\n",
    "\n",
    "        # Evaluation\n",
    "        print(\"\\nEvaluation：\")\n",
    "        final_loss, final_accuracy = model.evaluate(x_test, y_test)\n",
    "        print(\"loss= \", final_loss)\n",
    "        print(\"accuracy= \", final_accuracy)\n",
    "    \n",
    "    \n",
    "        print(\"success!\")\n",
    "        model.save('vgg_cifar100.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cifar10(dataset):\n",
    "    \n",
    "        (x_train, y_train), (x_test, y_test) = dataset.load_data() #original size train(xxx, 28, 28),test(xxx)\n",
    "        \n",
    "        #translate the data to image\n",
    "        x_train = x_train.astype(\"float32\")\n",
    "        x_test = x_test.astype(\"float32\")\n",
    "\n",
    "        #normalization\n",
    "        x_train /= 255\n",
    "        x_test /= 255\n",
    "        \n",
    "        #translate y_train and y_test to “one hot” form\n",
    "        y_train = utils.to_categorical(y_train,10) \n",
    "        y_test = utils.to_categorical(y_test,10)\n",
    "        \n",
    "        \n",
    "        model = VGG(10) #classes is 10\n",
    "        model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "        metrics=['accuracy'])\n",
    "        \n",
    "        print(\"\\nTraining：\")\n",
    "        model.fit(x_train, y_train, batch_size= 128, epochs= 25)\n",
    "\n",
    "        # Evaluation\n",
    "        print(\"\\nEvaluation：\")\n",
    "        final_loss, final_accuracy = model.evaluate(x_test, y_test)\n",
    "        print(\"loss= \", final_loss)\n",
    "        print(\"accuracy= \", final_accuracy)\n",
    "    \n",
    "    \n",
    "        print(\"success!\")\n",
    "        model.save('vgg_cifar10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training：\n",
      "Epoch 1/25\n",
      "  3/391 [..............................] - ETA: 29:50 - loss: 2.5763 - accuracy: 0.0938"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ed906c858874>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_cifar10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-bf73b258a27a>\u001b[0m in \u001b[0;36mtrain_cifar10\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTraining：\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset1 = cifar10\n",
    "train_cifar10(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training：\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 2684s 7s/step - loss: 4.4611 - accuracy: 0.0347\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2309s 6s/step - loss: 3.7219 - accuracy: 0.1243\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 1878s 5s/step - loss: 3.3559 - accuracy: 0.1808\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 1879s 5s/step - loss: 3.1263 - accuracy: 0.2189\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 1886s 5s/step - loss: 2.9710 - accuracy: 0.2462\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 1903s 5s/step - loss: 2.8271 - accuracy: 0.2761\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 1876s 5s/step - loss: 2.7038 - accuracy: 0.3038\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 1591s 4s/step - loss: 2.5772 - accuracy: 0.3308\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 1468s 4s/step - loss: 2.4818 - accuracy: 0.3536\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 1466s 4s/step - loss: 2.3708 - accuracy: 0.3743\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 1457s 4s/step - loss: 2.2735 - accuracy: 0.3923\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 1474s 4s/step - loss: 2.2099 - accuracy: 0.4067\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 1470s 4s/step - loss: 2.1278 - accuracy: 0.4268\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 1460s 4s/step - loss: 2.0199 - accuracy: 0.4481\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 1462s 4s/step - loss: 1.9409 - accuracy: 0.4602\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 1466s 4s/step - loss: 1.8451 - accuracy: 0.4842\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 1406s 4s/step - loss: 1.8071 - accuracy: 0.4891\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 1416s 4s/step - loss: 1.6997 - accuracy: 0.5098\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 1437s 4s/step - loss: 1.6439 - accuracy: 0.5240\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 1472s 4s/step - loss: 1.5758 - accuracy: 0.5382\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 1778s 5s/step - loss: 1.5064 - accuracy: 0.5571\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 1700s 4s/step - loss: 1.4435 - accuracy: 0.5703\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 1693s 4s/step - loss: 1.3941 - accuracy: 0.5833\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 1504s 4s/step - loss: 1.3242 - accuracy: 0.5983\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 1556s 4s/step - loss: 1.2670 - accuracy: 0.6092\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 1533s 4s/step - loss: 1.2171 - accuracy: 0.6250\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 1481s 4s/step - loss: 1.1579 - accuracy: 0.6425\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 1516s 4s/step - loss: 1.1110 - accuracy: 0.6522\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 1611s 4s/step - loss: 1.0824 - accuracy: 0.6582\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 1732s 4s/step - loss: 1.0150 - accuracy: 0.6781\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 1748s 4s/step - loss: 0.9836 - accuracy: 0.6873\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 1509s 4s/step - loss: 0.9929 - accuracy: 0.6854\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2458s 6s/step - loss: 0.9431 - accuracy: 0.6951\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2050s 5s/step - loss: 0.9185 - accuracy: 0.7050\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 1894s 5s/step - loss: 0.8665 - accuracy: 0.7160\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 1798s 5s/step - loss: 0.8513 - accuracy: 0.7254\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 1981s 5s/step - loss: 0.8263 - accuracy: 0.7331\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 1486s 4s/step - loss: 0.7742 - accuracy: 0.7448\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 1481s 4s/step - loss: 0.8019 - accuracy: 0.7424\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 1478s 4s/step - loss: 0.7792 - accuracy: 0.7502\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 1473s 4s/step - loss: 0.7409 - accuracy: 0.7595\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 1442s 4s/step - loss: 0.6975 - accuracy: 0.7695\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 1819s 5s/step - loss: 0.6896 - accuracy: 0.7746\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 2259s 6s/step - loss: 0.6436 - accuracy: 0.7884\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 1900s 5s/step - loss: 0.6250 - accuracy: 0.7929\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 1655s 4s/step - loss: 0.6273 - accuracy: 0.7914\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 1732s 4s/step - loss: 0.6022 - accuracy: 0.8002\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 1542s 4s/step - loss: 0.5770 - accuracy: 0.8083\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 1453s 4s/step - loss: 0.5705 - accuracy: 0.8125\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 1450s 4s/step - loss: 0.5577 - accuracy: 0.8135\n",
      "\n",
      "Evaluation：\n",
      "313/313 [==============================] - 69s 216ms/step - loss: 4.3975 - accuracy: 0.4637\n",
      "loss=  4.39747953414917\n",
      "accuracy=  0.46369999647140503\n",
      "success!\n"
     ]
    }
   ],
   "source": [
    "dataset2 = cifar100\n",
    "train_cifar100(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
