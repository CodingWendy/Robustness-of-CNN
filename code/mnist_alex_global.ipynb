{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist \n",
    "import matplotlib.pyplot as plt \n",
    "from keras.optimizers import Adam \n",
    "from keras import utils \n",
    "import numpy as np \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.keras.models import load_model \n",
    "\n",
    "dataset = mnist\n",
    "(x_train, y_train), (x_test, y_test) = dataset.load_data() #translate the data to image \n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0], -1).astype(\"float64\")\n",
    "\n",
    "#normalization \n",
    "x_test /= 255\n",
    "\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "alexnet = load_model('Model/alexnet_mnist.h5')#load lenet5 model trained with mnist dataset \n",
    "alexnet.compile(optimizer=Adam(),loss='sparse_categorical_crossentropy',metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta is reduced by 0.0001, the new beta is 0.10781\n",
      "Beta is reduced by 0.0001, the new beta is 0.10771\n",
      "Beta is reduced by 0.0001, the new beta is 0.10761\n",
      "Beta is reduced by 0.0001, the new beta is 0.10751\n",
      "Beta is reduced by 0.0001, the new beta is 0.10740999999999999\n",
      "Beta is reduced by 0.0001, the new beta is 0.10730999999999999\n",
      "Beta is reduced by 0.0001, the new beta is 0.10720999999999999\n",
      "Beta is reduced by 0.0001, the new beta is 0.10710999999999998\n",
      "Beta is reduced by 0.0001, the new beta is 0.10700999999999998\n",
      "Beta is reduced by 0.0001, the new beta is 0.10690999999999998\n",
      "Beta is reduced by 0.0001, the new beta is 0.10680999999999997\n",
      "Beta is reduced by 0.0001, the new beta is 0.10670999999999997\n",
      "Beta is reduced by 0.0001, the new beta is 0.10660999999999997\n",
      "Beta is reduced by 0.0001, the new beta is 0.10650999999999997\n",
      "Beta is reduced by 0.0001, the new beta is 0.10640999999999996\n",
      "Beta is reduced by 0.0001, the new beta is 0.10630999999999996\n",
      "Beta is reduced by 0.0001, the new beta is 0.10620999999999996\n",
      "Beta is reduced by 0.0001, the new beta is 0.10610999999999995\n",
      "Beta is reduced by 0.0001, the new beta is 0.10600999999999995\n",
      "Beta is reduced by 0.0001, the new beta is 0.10590999999999995\n",
      "Beta is reduced by 0.0001, the new beta is 0.10580999999999995\n",
      "Beta is reduced by 0.0001, the new beta is 0.10570999999999994\n",
      "Beta is reduced by 0.0001, the new beta is 0.10560999999999994\n",
      "Beta is reduced by 0.0001, the new beta is 0.10550999999999994\n",
      "Beta is reduced by 0.0001, the new beta is 0.10540999999999993\n",
      "Beta is reduced by 0.0001, the new beta is 0.10530999999999993\n",
      "Beta is reduced by 0.0001, the new beta is 0.10520999999999993\n",
      "Beta is reduced by 0.0001, the new beta is 0.10510999999999993\n",
      "Beta is reduced by 0.0001, the new beta is 0.10500999999999992\n",
      "Beta is reduced by 0.0001, the new beta is 0.10490999999999992\n",
      "Beta is reduced by 0.0001, the new beta is 0.10480999999999992\n",
      "Beta is reduced by 0.0001, the new beta is 0.10470999999999991\n",
      "Beta is reduced by 0.0001, the new beta is 0.10460999999999991\n",
      "Beta is reduced by 0.0001, the new beta is 0.10450999999999991\n",
      "Beta is reduced by 0.0001, the new beta is 0.1044099999999999\n",
      "Beta is reduced by 0.0001, the new beta is 0.1043099999999999\n",
      "Beta is reduced by 0.0001, the new beta is 0.1042099999999999\n",
      "Beta is reduced by 0.0001, the new beta is 0.1041099999999999\n",
      "Beta is reduced by 0.0001, the new beta is 0.1040099999999999\n",
      "Beta is reduced by 0.0001, the new beta is 0.10390999999999989\n",
      "Beta is reduced by 0.0001, the new beta is 0.10380999999999989\n",
      "Beta is reduced by 0.0001, the new beta is 0.10370999999999989\n",
      "Beta is reduced by 0.0001, the new beta is 0.10360999999999988\n",
      "Beta is reduced by 0.0001, the new beta is 0.10350999999999988\n",
      "Beta is reduced by 0.0001, the new beta is 0.10340999999999988\n",
      "Beta is reduced by 0.0001, the new beta is 0.10330999999999987\n",
      "Beta is reduced by 0.0001, the new beta is 0.10320999999999987\n",
      "Beta is reduced by 0.0001, the new beta is 0.10310999999999987\n",
      "Beta is reduced by 0.0001, the new beta is 0.10300999999999987\n",
      "Beta is reduced by 0.0001, the new beta is 0.10290999999999986\n",
      "Beta is reduced by 0.0001, the new beta is 0.10280999999999986\n",
      "Beta is reduced by 0.0001, the new beta is 0.10270999999999986\n",
      "Beta is reduced by 0.0001, the new beta is 0.10260999999999985\n",
      "Beta is reduced by 0.0001, the new beta is 0.10250999999999985\n",
      "Beta is reduced by 0.0001, the new beta is 0.10240999999999985\n",
      "Beta is reduced by 0.0001, the new beta is 0.10230999999999985\n",
      "Beta is reduced by 0.0001, the new beta is 0.10220999999999984\n",
      "Beta is reduced by 0.0001, the new beta is 0.10210999999999984\n",
      "Beta is reduced by 0.0001, the new beta is 0.10200999999999984\n",
      "Beta is reduced by 0.0001, the new beta is 0.10190999999999983\n",
      "Beta is reduced by 0.0001, the new beta is 0.10180999999999983\n",
      "Beta is reduced by 0.0001, the new beta is 0.10170999999999983\n",
      "Beta is reduced by 0.0001, the new beta is 0.10160999999999983\n",
      "Beta is reduced by 0.0001, the new beta is 0.10150999999999982\n",
      "Beta is reduced by 0.0001, the new beta is 0.10140999999999982\n",
      "Beta is reduced by 0.0001, the new beta is 0.10130999999999982\n",
      "Beta is reduced by 0.0001, the new beta is 0.10120999999999981\n",
      "Beta is reduced by 0.0001, the new beta is 0.10110999999999981\n",
      "Beta is reduced by 0.0001, the new beta is 0.10100999999999981\n",
      "Beta is reduced by 0.0001, the new beta is 0.1009099999999998\n",
      "Beta is reduced by 0.0001, the new beta is 0.1008099999999998\n",
      "Beta is reduced by 0.0001, the new beta is 0.1007099999999998\n",
      "Beta is reduced by 0.0001, the new beta is 0.1006099999999998\n",
      "Beta is reduced by 0.0001, the new beta is 0.1005099999999998\n",
      "Beta is reduced by 0.0001, the new beta is 0.10040999999999979\n",
      "Beta is reduced by 0.0001, the new beta is 0.10030999999999979\n",
      "Beta is reduced by 0.0001, the new beta is 0.10020999999999979\n",
      "Beta is reduced by 0.0001, the new beta is 0.10010999999999978\n",
      "Beta is reduced by 0.0001, the new beta is 0.10000999999999978\n",
      "Beta is reduced by 0.0001, the new beta is 0.09990999999999978\n",
      "Beta is reduced by 0.0001, the new beta is 0.09980999999999977\n",
      "Beta is reduced by 0.0001, the new beta is 0.09970999999999977\n",
      "Beta is reduced by 0.0001, the new beta is 0.09960999999999977\n",
      "Beta is reduced by 0.0001, the new beta is 0.09950999999999977\n",
      "Beta is reduced by 0.0001, the new beta is 0.09940999999999976\n",
      "Beta is reduced by 0.0001, the new beta is 0.09930999999999976\n",
      "Beta is reduced by 0.0001, the new beta is 0.09920999999999976\n",
      "Beta is reduced by 0.0001, the new beta is 0.09910999999999975\n",
      "Beta is reduced by 0.0001, the new beta is 0.09900999999999975\n",
      "Beta is reduced by 0.0001, the new beta is 0.09890999999999975\n",
      "Beta is reduced by 0.0001, the new beta is 0.09880999999999975\n",
      "Beta is reduced by 0.0001, the new beta is 0.09870999999999974\n",
      "Beta is reduced by 0.0001, the new beta is 0.09860999999999974\n",
      "Beta is reduced by 0.0001, the new beta is 0.09850999999999974\n",
      "Beta is reduced by 0.0001, the new beta is 0.09840999999999973\n",
      "Beta is reduced by 0.0001, the new beta is 0.09830999999999973\n",
      "Beta is reduced by 0.0001, the new beta is 0.09820999999999973\n",
      "Beta is reduced by 0.0001, the new beta is 0.09810999999999973\n",
      "Beta is reduced by 0.0001, the new beta is 0.09800999999999972\n",
      "Beta is reduced by 0.0001, the new beta is 0.09790999999999972\n",
      "Beta is reduced by 0.0001, the new beta is 0.09780999999999972\n",
      "Beta is reduced by 0.0001, the new beta is 0.09770999999999971\n",
      "Beta is reduced by 0.0001, the new beta is 0.09760999999999971\n",
      "Beta is reduced by 0.0001, the new beta is 0.09750999999999971\n",
      "Beta is reduced by 0.0001, the new beta is 0.0974099999999997\n",
      "Beta is reduced by 0.0001, the new beta is 0.0973099999999997\n",
      "Beta is reduced by 0.0001, the new beta is 0.0972099999999997\n",
      "Beta is reduced by 0.0001, the new beta is 0.0971099999999997\n",
      "Beta is reduced by 0.0001, the new beta is 0.0970099999999997\n",
      "Beta is reduced by 0.0001, the new beta is 0.09690999999999969\n",
      "Beta is reduced by 0.0001, the new beta is 0.09680999999999969\n",
      "Beta is reduced by 0.0001, the new beta is 0.09670999999999969\n",
      "Beta is reduced by 0.0001, the new beta is 0.09660999999999968\n",
      "Beta is reduced by 0.0001, the new beta is 0.09650999999999968\n",
      "Beta is reduced by 0.0001, the new beta is 0.09640999999999968\n",
      "Beta is reduced by 0.0001, the new beta is 0.09630999999999967\n",
      "Beta is reduced by 0.0001, the new beta is 0.09620999999999967\n",
      "Beta is reduced by 0.0001, the new beta is 0.09610999999999967\n",
      "Beta is reduced by 0.0001, the new beta is 0.09600999999999967\n",
      "Beta is reduced by 0.0001, the new beta is 0.09590999999999966\n",
      "global robustness formula satisfied\n",
      "max safe distance: 0.09590999999999966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.09590999999999966"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta = 0.10791\n",
    "sample(x_test,y_test,beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(x_test,y_test,beta):\n",
    "    mean = np.zeros(2)  \n",
    "    cov = np.eye(2)\n",
    "    \n",
    "    for i in range(x_test.shape[0]):\n",
    "        count = 0\n",
    "        while True:\n",
    "            p = np.random.multivariate_normal(mean, cov,(28,28)) #sample formula\n",
    "            p = p.reshape(-1,28,28,1)\n",
    "            neighbour = p[0] + x_test[i]*255\n",
    "            neighbour /= 255\n",
    "            distance=np.linalg.norm(p[0]) \n",
    "            distance /= 255\n",
    "            #print(distance)\n",
    "            if (distance < beta or distance == beta):\n",
    "                output = lenet5.predict(neighbour.reshape(-1, 28, 28, 1),batch_size=128)[0]\n",
    "                proba = softmax(output)\n",
    "                pred = np.argmax(proba)\n",
    "                label = y_test[i]\n",
    "                \n",
    "                if(pred == label): \n",
    "                    count+=1\n",
    "\n",
    "                else:  #if there are some iamges inside beta cannot have the same label, beta will be decreased\n",
    "                    beta = beta-0.0001\n",
    "                    print(\"Beta is reduced by 0.0001, the new beta is\",beta)  \n",
    "                    i-=1\n",
    "                    break\n",
    "                    \n",
    "            if(count<600):  \n",
    "                continue\n",
    "                \n",
    "            if(count==600):  \n",
    "                #local robustness formula satisfied\n",
    "                break\n",
    "                \n",
    "    print(\"global robustness formula satisfied\")    \n",
    "    print(\"max safe distance:\",beta)\n",
    "    return beta\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x-np.max(x))\n",
    "    return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
